<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Chen Wang</title>
    <link href='https://fonts.googleapis.com/css?family=Pinyon Script' rel='stylesheet'>
    <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro' rel='stylesheet' type='text/css'>
    <link rel="icon" type="image/x-icon" href="images/favicon1.svg">
    <!--Use downloaded bootstrap 5.1.3 -->
    <!-- <link href="bootstrap.min.css" rel="stylesheet"> -->
    <link href="https://db.onlinewebfonts.com/c/242a828d266472665bf6ad46819772eb?family=STXingkai" rel="stylesheet">
    <!-- <script src="bootstrap.bundle.min.js"></script> -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
    <link rel="stylesheet" href="style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>
    <!-- <link href="https://fonts.googleapis.com/css2?family=Bitter:ital,wght@0,100..900;1,100..900&display=swap"
        rel="stylesheet"> -->

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-26S5T791WC"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-26S5T791WC');
    </script>
</head>

<body>
    <div class="header">
        <div class="nav-brand">
            <a href="#home">Chen Wang</a>
        </div>
        <nav class="nav-links">
            <a href="#home" class="active">Home</a>
            <a href="#publications">Publications</a>
            <a href="#services">Services</a>
            <a href="#awards">Awards</a>
            <a href="./posts.html">Posts</a>
        </nav>
    </div>

    <div class="container" id="home">
        <div class="row justify-content-center">
            <div class="col-12">
                <div class="hero-panel">
                    <div class="row align-items-center intro hero-section">
                        <div class="links1 col-12 col-lg-9 hero-card">
                            <h1 class="hero-name text-center text-lg-start">Chen Wang&nbsp&nbsp<span
                                    style="font-family: STXingkai;">ÁéãÁêõ</span>
                            </h1>
                            <p>I am a CIS PhD student (Fall 2023 - Now) at the University of Pennsylvania,
                                where I am advised by <a href="https://lingjie0206.github.io/">Prof.
                                    Lingjie Liu</a>. My research has been partly
                                supported by <a href="https://www.meshy.ai/blog/fellowship-2025">Meshy AI
                                    Fellowship</a>.</p>
                            <p>
                                I am interested in Generative AI and its applications, including but not limited to 3D
                                vision
                                and
                                computer graphics. I am open to research discussions, feel free to drop me an email!
                            </p>
                            <p>I did my undergraduate and master study in CS at Tsinghua University, working with Prof.
                                <a href=" https://scholar.google.com/citations?user=LDb4tb0AAAAJ&hl=en&oi=ao">Shi-Min
                                    Hu</a>
                                and <a href="https://scholar.google.com/citations?user=AWtV-EQAAAAJ&hl=en&oi=ao">Prof.
                                    Song-Hai
                                    Zhang</a>.
                            </p>
                            <!-- <p class=" quote">"Our primary drive in life is not pleasure, but the discovery and pursuit of
                        what we personally find meaningful. (In Man's Search For Meaning)"</p> -->
                            <div class="links hero-links text-center text-lg-start">
                                <a href="mailto:cw.chenwang@outlook.com">Email</a>
                                <a href="https://scholar.google.com/citations?user=5cY3Ho4AAAAJ&hl=en">Google
                                    Scholar</a>
                                <a href="https://x.com/chenwangcw">Twitter</a>
                                <a href="https://www.linkedin.com/in/chen-wang-05509b161/">Linkedin</a>
                            </div>
                        </div>
                        <div class="col-12 col-lg-3 hero-avatar text-center">
                            <img src="data/pic.png" class="avatar img-fluid rounded-circle">
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="row justify-content-center" id="news">
            <div class="col-12">
                <p class="section-name" style="margin-bottom: 3pt; ">News</p>
                <div class="exp-list">
                    <ul>
                        <li>&#x2022;&nbsp (05/2025) Join Adobe Research for summer internship. Welcome to connect at Bay
                            Area.</a></li>
                        <li>&#x2022;&nbsp (04/2024) We have created an <a
                                href="https://github.com/cwchenwang/awesome-4d-generation">awesome list of papers on 4D
                                generation.</a></li>
                        <li>&#x2022;&nbsp (01/2024) Check out my <a
                                href="https://github.com/cwchenwang/awesome-3d-diffusion">GitHub Repo</a> on a list of
                            papers on "Diffusion Models for
                            3D
                            Generation" and <a href="data/survey.pdf">the survey paper</a>.
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="row justify-content-center" id="publications">

            <div class="col-12">
                <p class="section-name" style="margin-bottom: 3pt; ">Selected Publications</p>
                <p style="margin-bottom: 3pt;">* denotes equal contribution</p>
                <div class="row justify-content-center pub-item">
                    <div class="col-md-3">
                        <img src="data/paper_thumbnail/physctrl.png" alt="boot" class="img-fluid mx-auto rounded">
                    </div>
                    <div class="col-md-9 paper-info-v1">
                        <!-- Paper Title -->
                        <h3 class="paper-title">PhysCtrl: Generative Physics for Controllable and Physics-Grounded Video
                            Generation</h3>
                        <p class="paper-authors"><strong>Chen Wang*</strong>, Chuhao Chen*, Yiming Huang, Zhiyang Dou,
                            Yuan
                            Liu,
                            Jiatao Gu, Lingjie Liu</p>
                        <p>NeurIPS, 2025</p>
                        <p><a href="https://arxiv.org/abs/2509.20358">Paper</a>&nbsp;|&nbsp;<a
                                href="https://cwchenwang.github.io/physctrl">Project Page</a>&nbsp;|&nbsp;<a
                                href="https://github.com/cwchenwang/physctrl">Code</a></p>
                    </div>
                </div>
                <div class="row justify-content-center pub-item">
                    <div class="col-md-3"><model-viewer tone-mapping="neutral"
                            src="data/paper_thumbnail/animal_character.glb" orientation="0deg 0deg 180deg"
                            shadow-intensity="1" camera-controls="" touch-action="pan-y"
                            ar-status="not-presenting"></model-viewer></div>
                    <div class="col-md-9 paper-info-v1">
                        <!-- Paper Title -->
                        <h3 class="paper-title">GECOü¶é: Generative Image-to-3D within a SECOnd</h3>
                        <p class="paper-authors"><strong>Chen Wang</strong>, Jiatao Gu, Xiaoxiao Long, Yuan Liu, Lingjie
                            Liu</p>
                        <p>IEEE TVCG, 2025</p>
                        <p><a href="https://arxiv.org/abs/2405.20327">Paper</a>&nbsp;|&nbsp;<a
                                href="https://cwchenwang.github.io/geco/">Project Page</a>&nbsp;|&nbsp;<a
                                href="https://github.com/cwchenwang/geco">Code</a></p>
                    </div>
                </div>
                <div class="row justify-content-center pub-item">
                    <div class="col-md-3">
                        <img src="data/paper_thumbnail/zero12g.png" alt="boot" class="img-fluid mx-auto rounded">
                    </div>
                    <div class="col-md-9 paper-info-v1">
                        <!-- Paper Title -->
                        <h3 class="paper-title">Zero-1-to-G: Taming Pretrained 2D Diffusion Model for Direct 3D
                            Generation</h3>
                        <p class="paper-authors">Xuyi Meng*, <strong>Chen Wang*</strong>, Jiahui Lei, Kostas Daniilidis,
                            Jiatao Gu,
                            Lingjie Liu</p>
                        <p>TMLR, 2025</p>
                        <p><a href="https://arxiv.org/pdf/2501.05427">Paper</a>&nbsp;|&nbsp;<a
                                href="https://mengxuyigit.github.io/projects/zero-1-to-G/">Project Page</a></p>
                    </div>
                </div>
                <!-- <div class="row justify-content-center pub-item">
                    <div class="col-md-3">
                        <img src="data/paper_thumbnail/boot.jpeg" alt="boot" class="img-fluid mx-auto rounded">
                    </div>
                    <div class="col-md-9 paper-info-v1">
                        Data-free Distillation of Denoising Diffusion Models with Bootstrapping
                        <p class="paper-authors">Jiatao Gu, <strong>Chen Wang</strong>, Shuangfei Zhai, Yizhe Zhang, Lingjie Liu,
                            Josh Susskind</p>
                        <p>ICML, 2024</p>
                        <p><a
                                href="https://openreview.net/pdf/91ce5baf1cb9a852eaf8a1706470b91358790b4a.pdf">Paper</a>&nbsp;|&nbsp;<a
                                href="https://machinelearning.apple.com/research/boot">Project Page</a>
                    </div>
                </div> -->

                <div class="row justify-content-center pub-item">
                    <div class="col-md-3">
                        <img src="data/paper_thumbnail/dreameditor.png" alt="dreameditor"
                            class="img-fluid mx-auto rounded">
                    </div>
                    <div class="col-md-9 paper-info-v1">
                        <h3 class="paper-title">DreamEditor: Text-Driven 3D Scene Editing with Neural Fields</h3>
                        <p class="paper-authors">Jingyu Zhuang*, <strong>Chen Wang*</strong>, Liang Lin,
                            Lingjie Liu, Guanbin Li</p>
                        <p>SIGGRAPH Asia, 2023</p>
                        <p><a href="https://arxiv.org/abs/2306.13455">Paper</a>&nbsp;|&nbsp;<a
                                href="https://zjy526223908.github.io/DreamEditor/">Project Page</a>&nbsp;|&nbsp;<a
                                href="https://github.com/zjy526223908/DreamEditor">Code</a></p>
                    </div>
                </div>

                <div class="row justify-content-center pub-item">
                    <div class="col-md-3">
                        <img src="data/paper_thumbnail/outdoor-nerf-depth.png" alt="outdoor-nerf-depth"
                            class="img-fluid mx-auto rounded">
                    </div>
                    <div class="col-md-9 paper-info-v1">
                        <h3 class="paper-title">Digging into Depth Priors for Outdoor Neural Radiance Fields</h3>
                        <p class="paper-authors"><strong>Chen Wang</strong>, Jiadai Sun, Lina Liu, Chenming Wu, Zhelun
                            Shen,
                            Dayan
                            Wu, Yuchao Dai,
                            Liangjun Zhang</p>
                        <p>ACM MM (Oral), 2023</p>
                        <a
                            href="https://cwchenwang.github.io/outdoor-nerf-depth/data/paper.pdf">Paper</a>&nbsp;|&nbsp;<a
                            href="https://cwchenwang.github.io/outdoor-nerf-depth">Project Page</a>&nbsp;|&nbsp;<a
                            href="https://github.com/cwchenwang/outdoor-nerf-depth">Code</a>
                    </div>
                </div>
                <!-- 
                <div class="row justify-content-center pub-item">
                    <div class="col-md-3">
                        <img src="data/paper_thumbnail/structnerf.png" alt="structnerf"
                            class="img-fluid mx-auto rounded">
                    </div>
                    <div class="col-md-9 paper-info-v1">
                        StructNeRF: Neural Radiance Fields for Indoor Scenes with Structural Hints
                        <p class="paper-authors">Zheng Chen, <strong>Chen Wang</strong>, Yuan-Chen Guo, Song-Hai Zhang</p>
                        <p>IEEE TPAMI, 2023</p>
                    </div>
                </div> -->

                <div class="row justify-content-center pub-item">
                    <div class="col-md-3">
                        <img src="data/paper_thumbnail/deepportraitdrawing.png" alt="deepportraitdrawing"
                            class="img-fluid mx-auto rounded">
                    </div>
                    <div class="col-md-9 paper-info-v1">
                        <h3 class="paper-title">DeepPortraitDrawing: Generating Human Body Images from Freehand Sketches
                        </h3>
                        <p class="paper-authors"><strong>Chen Wang*</strong>, Xian Wu*, Hongbo Fu, Ariel Shamir,
                            Song-Hai
                            Zhang
                        </p>
                        <p>Computer & Graphics (CAD/Graphics Oral), 2023</p>
                    </div>
                </div>

                <div class="row justify-content-center pub-item">
                    <div class="col-md-3">
                        <video autoplay loop muted controls class="mx-auto d-block">
                            <source src="data/paper_thumbnail/nerf-sr.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="col-md-9 paper-info-v1">
                        <h3 class="paper-title">NeRF-SR: High-Quality Neural Radiance Fields using Super-sampling</h3>
                        <p class="paper-authors"><strong>Chen Wang</strong>, Xian Wu, Yuan-Chen Guo, Song-Hai Zhang,
                            Yu-Wing Tai,
                            Shi-Min Hu</p>
                        <p>ACM MM, 2022</p>
                        <a href="https://arxiv.org/abs/2112.01759">Paper</a>&nbsp;|&nbsp;<a
                            href="https://cwchenwang.github.io/NeRF-SR">Project Page</a>&nbsp;|&nbsp;<a
                            href="https://github.com/cwchenwang/NeRF-SR">Code</a>
                    </div>
                </div>

                <div class="row justify-content-center pub-item">
                    <div class="col-md-3">
                        <img src="data/paper_thumbnail/rotation-gains.png" alt="rotation-gains"
                            class="img-fluid mx-auto rounded">
                    </div>
                    <div class="col-md-9 paper-info-v1">
                        <h3 class="paper-title">On Rotation Gains Within and Beyond Perceptual Limitations for Seated VR
                        </h3>
                        <p class="paper-authors"><strong>Chen Wang</strong>, Song-Hai Zhang, Yi-Zhuo Zhang, Stefanie
                            Zollmann,
                            Shi-Min
                            Hu</p>
                        <p>IEEE TVCG, 2022</p>
                    </div>
                </div>
            </div>
        </div>
        <div class="row justify-content-center" id="services">
            <div class="col-12">
                <p class="section-name">Services</p>
                <div class="exp-list">
                    <ul>
                        <li>Conference Reviewer: CVPR, ICCV, ECCV, ICML, ICLR, NeurIPS, SIGGRAPH Asia, AAAI, ACMMM, 3DV,
                            WACV,
                            PG
                        </li>
                        <li>Journal Reviewer: PAMI, ToG, TVCG, TIP, CVMJ
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="row justify-content-center" id="awards">
            <div class="col-12">
                <p class="section-name">Honors and Awards</p>
                <div class="exp-list">
                    <ul>
                        <li>2025 Meshy AI Fellowship
                        </li>
                        <li>
                            2023 Donor-named Fellowship, UPenn
                        </li>
                        <li>2022 National Scholarship
                        </li>
                        <li>2022 Siebel Scholarship</li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="row justify-content-center">
            <div class="col-3">
                <script type="text/javascript" id="clustrmaps"
                    src="//clustrmaps.com/map_v2.js?d=S31GDEkuyTI1cAIMEWRZaWrVuS-0CFW0bIl3_ZDOvmk&cl=ffffff&w=a"></script>
            </div>
        </div>
        <footer class="text-center">
            <p>This website was last updated in Dec, 2025.</p>
            <p>¬© Copyright 2021 - Present</p>
        </footer>
    </div>

</body>

</html>