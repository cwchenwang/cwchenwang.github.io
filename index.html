<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Chen Wang</title>
    <link href='https://fonts.googleapis.com/css?family=Pinyon Script' rel='stylesheet'>
    <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro' rel='stylesheet' type='text/css'>
    <link rel="icon" type="image/x-icon" href="images/favicon.png">
    <!--Use downloaded bootstrap 5.1.3 -->
    <!-- <link href="bootstrap.min.css" rel="stylesheet"> -->
    <link href="https://db.onlinewebfonts.com/c/242a828d266472665bf6ad46819772eb?family=STXingkai" rel="stylesheet">
    <!-- <script src="bootstrap.bundle.min.js"></script> -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
    <link rel="stylesheet" href="style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>
    <!-- <link href="https://fonts.googleapis.com/css2?family=Bitter:ital,wght@0,100..900;1,100..900&display=swap"
        rel="stylesheet"> -->

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-26S5T791WC"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-26S5T791WC');
    </script>
</head>

<body>
    <div class="header">
        <!-- <a href="#">Chen Wang</a> -->
        <div class="ftheader">
            <a href="#home">Chen Wang</a>
        </div>
        <!-- ??? why the order is reversed -->
        <div class="ftsubheader">
            <a href="./posts.html">Posts</a>
        </div>
        <div class="ftsubheader">
            <a href="#awards">Awards</a>
        </div>
        <div class="ftsubheader">
            <a href="#services">Services</a>
        </div>
        <div class="ftsubheader">
            <a href="#publications">Publications</a>
        </div>
        <div class="ftsubheader">
            <a href="#home">Home</a>
        </div>
    </div>

    <div class="container" id="home">
        <div class="row justify-content-center intro">
            <div class="links1 col-9">
                <h1 class="text-center">Chen Wang&nbsp&nbsp<span style="font-family: STXingkai;">ÁéãÁêõ</span>
                </h1>
                <p>I am a CIS PhD student (Fall 2023 - Now) at the University of Pennsylvania,
                    where I have the pleasure to work with <a href="https://lingjie0206.github.io/">Prof.
                        Lingjie Liu</a>. I am affiliated with the Graphics Lab and GRASP lab. My
                    research interests are computer graphics and computer vision, with a focus on 3D/4D generative
                    models
                    and neural 3D representaions. My research is partly supported by <a
                        href="https://www.meshy.ai/blog/fellowship-2025">Meshy AI Fellowship</a>.
                </p>
                <p>I did my undergraduate and master study in CS at Tsinghua University, working with Prof.
                    <a href=" https://scholar.google.com/citations?user=LDb4tb0AAAAJ&hl=en&oi=ao">Shi-Min Hu</a>
                    and <a href="https://scholar.google.com/citations?user=AWtV-EQAAAAJ&hl=en&oi=ao">Prof. Song-Hai
                        Zhang</a>.
                </p>
                <!-- <p class=" quote">"Our primary drive in life is not pleasure, but the discovery and pursuit of
                        what we personally find meaningful. (In Man's Search For Meaning)"</p> -->
                <div class="links text-center">
                    <a href="mailto:cw.chenwang@outlook.com">Email</a>
                    <a href="data/CV_en.pdf">CV</a>
                    <a href="https://scholar.google.com/citations?user=5cY3Ho4AAAAJ&hl=en">Google Scholar</a>
                </div>
            </div>
            <div class="col-3">
                <img src="data/pic.png" class="avatar img-fluid rounded-circle">
            </div>
        </div>
        <div class="row justify-content-center" id="news">
            <div class="col-12">
                <p class="section-name" style="margin-bottom: 3pt; ">News</p>
                <div class="exp-list">
                    <ul>
                        <li>&#x2022;&nbsp (04/2024) We have created an <a
                                href="https://github.com/cwchenwang/awesome-4d-generation">awesome list of papers on 4D
                                generation.</a></li>
                        <li>&#x2022;&nbsp (01/2024) Check out my <a
                                href="https://github.com/cwchenwang/awesome-3d-diffusion">GitHub Repo</a> on a list of
                            papers on "Diffusion Models for
                            3D
                            Generation" and <a href="data/survey.pdf">the survey paper</a>.
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="row justify-content-center" id="publications">

            <div class="col-12">
                <p class="section-name" style="margin-bottom: 3pt; ">Selected Publications</p>
                <p style="margin-bottom: 3pt;">* denotes equal contribution</p>
                <div class="row justify-content-center pub-item">
                    <div class="col-md-4">
                        <img src="data/paper_thumbnail/vid2sim.JPG" alt="boot" class="img-fluid mx-auto rounded"
                            style="width: 80%; height: 110px; display: block;">
                    </div>
                    <div class="col-md-8 paper-info-v1">
                        <!-- Paper Title -->
                        Vid2Sim: Generalizable, Video-based Reconstruction of Appearance, Geometry and Physics for
                        Mesh-free Simulation
                        <p class="text-muted">Chuhao Chen, Zhiyang Dou, <u>Chen Wang</u>, Yiming Huang, Anjun Chen, Qiao
                            Feng,
                            Jiatao Gu, Lingjie Liu</p>
                        <p>CVPR, 2025</p>
                        <p>Coming Soon</p>
                    </div>
                </div>
                <div class="row justify-content-center pub-item">
                    <div class="col-md-4">
                        <video width="80%" height="auto" autoplay loop muted controls class="mx-auto d-block">
                            <source src="data/paper_thumbnail/protracker.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="col-md-8 paper-info-v1">
                        <!-- Paper Title -->
                        ProTracker: Probabilistic Integration for Robust and Accurate Point Tracking
                        <p class="text-muted">Tingyang Zhang, <u>Chen Wang</u>, Zhiyang Dou, Qingzhe Gao, Jiahui Lei,
                            Baoquan
                            Chen, Lingjie Liu</p>
                        <p>Arxiv, 2025</p>
                        <p><a href="https://arxiv.org/abs/2501.03220">Paper</a>&nbsp;|&nbsp;<a
                                href="https://michaelszj.github.io/protracker/">Project Page</a>&nbsp;|&nbsp;<a
                                href="https://github.com/Michaelszj/pro-tracker">Code</a></p>
                    </div>
                </div>
                <div class="row justify-content-center pub-item">
                    <div class="col-md-4 ''">
                        <img src="data/paper_thumbnail/zero12g.png" alt="boot" class="img-fluid mx-auto rounded"
                            style="width: 80%; height: 130px; display: block;">
                    </div>
                    <div class="col-md-8 paper-info-v1">
                        <!-- Paper Title -->
                        Zero-1-to-G: Taming Pretrained 2D Diffusion Model for Direct 3D Generation
                        <p class="text-muted">Xuyi Meng*, <u>Chen Wang*</u>, Jiahui Lei, Kostas Daniilidis, Jiatao Gu,
                            Lingjie Liu</p>
                        <p>Arxiv, 2025</p>
                        <p><a href="https://arxiv.org/pdf/2501.05427">Paper</a>&nbsp;|&nbsp;<a
                                href="https://mengxuyigit.github.io/projects/zero-1-to-G/">Project Page</a></p>
                    </div>
                </div>
                <div class="row justify-content-center pub-item">
                    <div class="col-md-4"><model-viewer tone-mapping="neutral"
                            src="data/paper_thumbnail/animal_character.glb" style="width: 100%;"
                            orientation="0deg 0deg 180deg" shadow-intensity="1" camera-controls="" touch-action="pan-y"
                            ar-status="not-presenting"></model-viewer></div>
                    <div class="col-md-8 paper-info-v1">
                        <!-- Paper Title -->
                        GECOü¶é: Generative Image-to-3D within a SECOnd
                        <p class="text-muted"><u>Chen Wang</u>, Jiatao Gu, Xiaoxiao Long, Yuan Liu, Lingjie Liu</p>
                        <p>Arxiv, 2024</p>
                        <p><a href="https://arxiv.org/abs/2405.20327">Paper</a>&nbsp;|&nbsp;<a
                                href="https://cwchenwang.github.io/geco/">Project Page</a>&nbsp;|&nbsp;<a
                                href="https://github.com/cwchenwang/geco">Code</a></p>
                    </div>
                </div>

                <div class="row justify-content-center pub-item">
                    <div class="col-md-4 ''">
                        <img src="data/paper_thumbnail/boot.jpeg" alt="boot" class="img-fluid mx-auto rounded"
                            style="width: 80%; height: 130px; display: block;">
                    </div>
                    <div class="col-md-8 paper-info-v1">
                        <!-- Paper Title -->
                        Data-free Distillation of Denoising Diffusion Models with Bootstrapping
                        <p class="text-muted">Jiatao Gu, <u>Chen Wang</u>, Shuangfei Zhai, Yizhe Zhang, Lingjie Liu,
                            Josh Susskind</p>
                        <p>International Conference on Machine Learning, 2024</p>
                        <p><a
                                href="https://openreview.net/pdf/91ce5baf1cb9a852eaf8a1706470b91358790b4a.pdf">Paper</a>&nbsp;|&nbsp;<a
                                href="https://machinelearning.apple.com/research/boot">Project Page</a>
                    </div>
                </div>

                <div class="row justify-content-center pub-item">
                    <div class="col-md-4 ''">
                        <img src="data/paper_thumbnail/dreameditor.png" alt="dreameditor" class="img-fluid mx-auto"
                            style="width: 80%; height: 130px; display: block;">
                    </div>
                    <div class="col-md-8 paper-info-v1">
                        <!-- Paper Title -->
                        DreamEditor: Text-Driven 3D Scene Editing with Neural Fields
                        <p class="text-muted">Jingyu Zhuang*, <u>Chen Wang*</u>, Liang Lin,
                            Lingjie Liu, Guanbin Li</p>
                        <p>SIGGRAPH Asia Conference Papers, 2023</p>
                        <p><a href="https://arxiv.org/abs/2306.13455">Paper</a>&nbsp;|&nbsp;<a
                                href="https://zjy526223908.github.io/DreamEditor/">Project Page</a>&nbsp;|&nbsp;<a
                                href="https://github.com/zjy526223908/DreamEditor">Code</a></p>
                    </div>
                </div>

                <div class="row justify-content-center pub-item">
                    <div class="col-md-4 ''">
                        <video width="80%" height="100%" autoplay loop muted controls>
                            <source src="data/paper_thumbnail/vmesh.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="col-md-8 paper-info-v1">
                        VMesh: Hybrid Volume-Mesh Representation for Efficient View Synthesis
                        <p class="text-muted">Yuan-Chen Guo, Yan-Pei Cao, <u>Chen Wang</u>,
                            Yu He, Ying Shan, Xiaohu Qie, Song-Hai Zhang</p>
                        <p>SIGGRAPH Asia Conference Papers, 2023</p>
                        <a href="https://arxiv.org/abs/2303.16184">Paper</a>&nbsp;|&nbsp;<a
                            href="https://bennyguo.github.io/vmesh/">Project Page</a>
                    </div>
                </div>

                <div class="row justify-content-center pub-item">
                    <div class="col-md-4 ''">
                        <img src="data/paper_thumbnail/outdoor-nerf-depth.png" alt="outdoor-nerf-depth"
                            class="img-fluid mx-auto rounded" style="width: 80%; display: block;">
                    </div>
                    <div class="col-md-8 paper-info-v1">
                        Digging into Depth Priors for Outdoor Neural Radiance Fields
                        <p class="text-muted"><u>Chen Wang</u>, Jiadai Sun, Lina Liu, Chenming Wu, Zhelun Shen,
                            Dayan
                            Wu, Yuchao Dai,
                            Liangjun Zhang</p>
                        <p>ACM International Conference on Multimedia (Oral), 2023</p>
                        <a
                            href="https://cwchenwang.github.io/outdoor-nerf-depth/data/paper.pdf">Paper</a>&nbsp;|&nbsp;<a
                            href="https://cwchenwang.github.io/outdoor-nerf-depth">Project Page</a>&nbsp;|&nbsp;<a
                            href="https://github.com/cwchenwang/outdoor-nerf-depth">Code</a>
                    </div>
                </div>

                <div class="row justify-content-center pub-item">
                    <div class="col-md-4 ''">
                        <img src="data/paper_thumbnail/structnerf.png" alt="structnerf"
                            class="img-fluid mx-auto rounded" style="width: 80%; height: 120px; display: block;">
                    </div>
                    <div class="col-md-8 paper-info-v1">
                        StructNeRF: Neural Radiance Fields for Indoor Scenes with Structural Hints
                        <p class="text-muted">Zheng Chen, <u>Chen Wang</u>, Yuan-Chen Guo, Song-Hai Zhang</p>
                        <p>IEEE Transactions on Pattern Analysis and Machine Intelligence, 2023</p>
                    </div>
                </div>

                <div class="row justify-content-center pub-item">
                    <div class="col-md-4 ''">
                        <img src="data/paper_thumbnail/deepportraitdrawing.png" alt="deepportraitdrawing"
                            class="img-fluid mx-auto rounded" style="width: 80%; height: 130px; display: block;">
                    </div>
                    <div class="col-md-8 paper-info-v1">
                        DeepPortraitDrawing: Generating Human Body Images from Freehand Sketches
                        <p class="text-muted"><u>Chen Wang*</u>, Xian Wu*, Hongbo Fu, Ariel Shamir, Song-Hai Zhang
                        </p>
                        <p>Computer & Graphics (CAD/Graphics Oral), 2023</p>
                    </div>
                </div>

                <div class="row justify-content-center pub-item">
                    <div class="col-md-4 ''">
                        <video width="70%" height="auto" autoplay loop muted controls class="mx-auto d-block">
                            <source src="data/paper_thumbnail/nerf-sr.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="col-md-8 paper-info-v1">
                        NeRF-SR: High-Quality Neural Radiance Fields using Super-sampling
                        <p class="text-muted"><u>Chen Wang</u>, Xian Wu, Yuan-Chen Guo, Song-Hai Zhang, Yu-Wing Tai,
                            Shi-Min Hu</p>
                        <p><em>ACM International Conference on Multimedia, 2022</em></p>
                        <a href="https://arxiv.org/abs/2112.01759">Paper</a>&nbsp;|&nbsp;<a
                            href="https://cwchenwang.github.io/NeRF-SR">Project Page</a>&nbsp;|&nbsp;<a
                            href="https://github.com/cwchenwang/NeRF-SR">Code</a>
                    </div>
                </div>

                <div class="row justify-content-center pub-item">
                    <div class="col-md-4 ''">
                        <img src="data/paper_thumbnail/rotation-gains.png" alt="rotation-gains"
                            class="img-fluid mx-auto" style="width: 80%; max-height: 130px; display: block;">
                    </div>
                    <div class="col-md-8 paper-info-v1">
                        On Rotation Gains Within and Beyond Perceptual Limitations for Seated VR
                        <p class="text-muted"><u>Chen Wang</u>, Song-Hai Zhang, Yi-Zhuo Zhang, Stefanie Zollmann,
                            Shi-Min
                            Hu</p>
                        <p>IEEE Transactions on Visualization and Computer Graphics,
                            2022</p>
                    </div>
                </div>
            </div>
        </div>
        <div class="row justify-content-center" id="services">
            <div class="col-12">
                <p class="section-name">Services</p>
                <div class="exp-list">
                    <ul>
                        <li>Conference Reviewer: CVPR, ICCV, ECCV, ICLR, NeurIPS, SIGGRAPH Asia, AAAI, ACMMM, 3DV, WACV,
                            PG
                        </li>
                        <li>Journal Reviewer: PAMI, TVCG, TIP
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="row justify-content-center" id="awards">
            <div class="col-12">
                <p class="section-name">Honors and Awards</p>
                <div class="exp-list">
                    <ul>
                        <li>2025 Meshy AI Fellowship
                        </li>
                        <li>2022 National Scholarship
                        </li>
                        <li>2022 Siebel Scholarship</li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="row justify-content-center">
            <div class="col-3">
                <script type="text/javascript" id="clustrmaps"
                    src="//clustrmaps.com/map_v2.js?d=S31GDEkuyTI1cAIMEWRZaWrVuS-0CFW0bIl3_ZDOvmk&cl=ffffff&w=a"></script>
            </div>
        </div>
        <footer class="text-center">
            <p>This website was last updated in Mar, 2025.</p>
            <p>¬© Copyright 2021 - Present</p>
        </footer>
    </div>

</body>

</html>